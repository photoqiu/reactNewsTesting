var a = [0, 1, 2, 3, 4, 5, 6];
var index = 0, current = 0; 
for(var i = 0; i < 50; i++) {
    if (index >= a.length) {
        index = 0;
    }
    if ( i % 7 === 0 && i > 1) {
      console.log("current numbers: ", i, a[0]);
    }
    current = a.splice(0, 1);
    a.push(current[0]);
    console.log("current:", a)
    index += 1;
}



漫反射：

漫反射数学模型RGB分量表示：`(R2,G2,B2) = (R1,G1,B1) x (R0,G0,B0) x cosθ`
// 角度值转化为弧度值
float radian = radians(60.0);
// reflectedLight的结果是(0.5,0,0)
vec3 reflectedLight = vec3(1.0,0.0,0.0) * vec3(1.0,0.0,0.0) * cos(radian)

镜面反射光的颜色 = 几何体表面基色 x 光线颜色 x 视线与反射光线的夹角余弦值<sup>n</sup>

环境反射光颜色 = 几何体表面基色 x 环境光颜色

总反射光线 = 漫反射光线 + 镜面反射光线 + 环境反射光线

在三维笛卡尔坐标系中，可以使用向量(x,y,z)来表示法向量，根据几何体表面的法向量和光线的方向， 就可以求解出光线入射角的余弦值，法向量的点积计算满足下面的公式，
为了方便计算，着色器语言内置了一个方法dot()用来求解两个向量之间的余弦值,已知向量a1(x1,y1,z1)、a2(x2，y2，z2)执行dot(a1，a2)可以求出两个向量a1、a2的余弦值。

attribute vec4 apos;//attribute声明vec4类型变量apos
attribute vec4 a_color;// attribute声明顶点颜色变量
attribute vec4 a_normal;//顶点法向量变量
uniform vec3 u_lightColor;// uniform声明平行光颜色变量
uniform vec3 u_lightPosition;// uniform声明平行光颜色变量
varying vec4 v_color;//varying声明顶点颜色插值后变量


WebGL屏幕坐标系、canvas坐标系和WebGL坐标系转换

<img src="canvas坐标系和WebGL坐标系转换.png" />
canvas坐标系转为webgl坐标系，webgl的坐标是x[-1, 1]，y[-1, 1]。

①获取canvas在浏览器客户区中的坐标
  var x = ev.clientX;
  var y = ev.clientY;
  var rect = ev.target.getBoundingClientRect();

图中的P点（x,y）为该点在屏幕坐标系下的坐标值；
图中canvas原点在屏幕坐标系下的坐标值为（a,b），即canvas在屏幕上左上角的位置坐标；
其中(a,b)坐标中：
  a = rect.left;
  b = rect.top;

此时求P点在canvas坐标系下的坐标，即将屏幕上的点P转换到cavans坐标系下：
  x' = x-a = x - rect.left;
  y' = y-b = y - rect.top;
(x - rect.left,y - rect.top)坐标为P点在canvas坐标系下的坐标值；

②将canvas坐标转换到webgl坐标系下
1.首先我们通过图片可知，canvas坐标系的Y轴和webgl的坐标系的Y轴方向是相反的，即在后面的转换过程中，y坐标值要进行取反操作。
2.通过代码我们可以获取canvas画布的宽和高：
  width = canvas.width;
  height = canvas.height;
则webgl原点在canvas坐标系中的位置（即canvas的中心点位置）坐标我们可以直接获得为（width/2,height/2）;

现在我们所得到的数据有：
P点在canvas坐标系下的坐标值:（x’,y’）->(x - rect.left,y - rect.top)
canvas的中心点在canvas坐标系下的坐标值：(width/2,height/2)
下一步，我们将canvas的原点平移到中心点（WebGL坐标系统的原点位于此处）
此时将canvas原点平移到中心点时，P点的坐标应该变为：
  x'' = x'-width/2
  y'' = y'-height/2
为了使得canvas平移后坐标系与WebGL坐标系完全一致，还需要对平移后的Y轴进行取反操作，即
  y'' = -1(y'-height/2)
此时的
（x'',y''）= (x'-width/2,height/2-y')) = ((x - rect.left)-width/2,height/2-(y - rect.top))

在对canvas坐标系进行平移、Y轴取反的操作后（此时的canvas坐标系与webgl坐标系原点位置和xy轴方向完全一致)。由于webgl坐标系的坐标区间为-1.0到1.0，所以最后一步我们将x''坐标除以width/2，将y''坐标除以height/2，
将canvas坐标映射到webgl坐标。
即P点坐标（x,y）最终转换后的坐标为（x''/(width/2), y''/(height/2)） = ( ((x - rect.left)-width/2)/(width/2),(height/2-(y - rect.top))/(height/2))
对应结果：
  x'' = ((x - rect.left) - width/2) / (width/2) = ((x - rect.left) - canvas.width/2) / (canvas.width / 2)
  y'' = (height/2 - (y - rect.top))/(height/2) = (canvas.height / 2-(y - rect.top)) / (canvas.height / 2)


模型围绕一个点运动
方法一：对方块A，基于世界坐标系平移，再基于自身/局部坐标系旋转，最后基于世界坐标系平移回去。
方法二：对方块A，基于自身坐标系平移，再基于自身/局部坐标系旋转，最后基于自身坐标系平移回去。

BufferGeometry 会缓存网格模型，性能要高效点。网格模型生成原理
1、Geometry 生成的模型是这样的 （代码）-> (CUP 进行数据处理，转化成虚拟3D数据) -> (GPU 进行数据组装，转化成像素点，准备渲染) -> 显示器
第二次操作时重复走这些流程。
2、BufferGeometry 生成模型流程 (代码) -> (CUP 进行数据处理，转化成虚拟3D数据) -> (GPU 进行数据组装，转化成像素点，准备渲染) -> (丢入缓存区) -> 显示器
第二次修改时，通过API直接修改缓存区数据，流程就变成了这样
(代码) -> (CUP 进行数据处理，转化成虚拟3D数据) -> (修改缓存区数据) -> 显示器
节约了GPU性能的运算性能

判断两条线段是否相交？
https://www.jb51.net/article/90104.htm

向量叉乘（行列式计算）：向量a（x1，y1），向量b（x2，y2）：
a x b = |x1, y1| = x1 * y2 - y1 * x2 |x2, y2|
首先我们要明白一个定理：
向量a×向量b（×为向量叉乘），若结果小于0，表示向量b在向量a的顺时针方向；
若结果大于0，表示向量b在向量a的逆时针方向；
若等于0，表示向量a与向量b平行。（顺逆时针是指两向量平移至起点相连，从某个方向旋转到另一个向量小于180度）。

https://www.cnblogs.com/tuyang1129/p/9390376.html
那如何来判断两线段是否相交呢？
假设有两条线段AB，CD，若AB，CD相交，我们可以确定：
1.线段AB与CD所在的直线相交，即点A和点B分别在直线CD的两边；
2.线段CD与AB所在的直线相交，即点C和点D分别在直线AB的两边；
上面两个条件同时满足是两线段相交的充要条件，所以我们只需要证明点A和点B分别在直线CD的两边，点C和点D分别在直线AB的两边，这样便可以证明线段AB与CD相交了。


function  judgeIntersect(x1,y1,x2,y2,x3,y3,x4,y4)
{

    //快速排斥：
    //两个线段为对角线组成的矩形，如果这两个矩形没有重叠的部分，那么两条线段是不可能出现重叠的
    //这里的确如此，这一步是判定两矩形是否相交
    //1.线段ab的低点低于cd的最高点（可能重合）
    //2.cd的最左端小于ab的最右端（可能重合）
    //3.cd的最低点低于ab的最高点（加上条件1，两线段在竖直方向上重合）
    //4.ab的最左端小于cd的最右端（加上条件2，两直线在水平方向上重合）
    //综上4个条件，两条线段组成的矩形是重合的
    //特别要注意一个矩形含于另一个矩形之内的情况

    if(!(Math.min(x1,x2) <= Math.max(x3,x4) && Math.min(y3,y4) <= Math.max(y1,y2) && Math.min(x3,x4) <= Math.max(x1,x2) && Math.min(y1,y2) <= Math.max(y3,y4)))
        return false;

    //跨立实验：
    //如果两条线段相交，那么必须跨立，就是以一条线段为标准，另一条线段的两端点一定在这条线段的两段
    //也就是说a b两点在线段cd的两端，c d两点在线段ab的两端
    var u,v,w,z
    u=(x3-x1)*(y2-y1)-(x2-x1)*(y3-y1);
    v=(x4-x1)*(y2-y1)-(x2-x1)*(y4-y1);
    w=(x1-x3)*(y4-y3)-(x4-x3)*(y1-y3);
    z=(x2-x3)*(y4-y3)-(x4-x3)*(y2-y3);
    return (u*v<=0.00000001 && w*z<=0.00000001);
}

在上面代码中涉及WebGL着色器三维向量vec3和四维向量vec4两种数据类型，比如光线的方向需要xyz三个分量描述，可以使用关键字vec3声明，比如顶点位置的齐次坐标(x,y,z,w), 包含透明度的RGB颜色模型RGBA(r,g,b,a)都需要四个分量描述，可以使用关键字vec4声明。

算法：判断一个直线是否和一个轮廓相交


算法：判断一组轮廓是顺时针还是逆时针
1、关于如何判定多边形是顺时针还是逆时针对于凸多边形而言，只需对某一个点计算叉积 = ((xi - xi-1),(yi - yi-1)) x ((xi+1 - xi),(yi+1 - yi)) = (xi - xi-1) * (yi+1 - yi) - (yi - yi-1) * (xi+1 - xi)
如果上式的值为正，逆时针；为负则是顺时针。

而对于一般的简单多边形，则需对于多边形的每一个点计算上述值，如果正值比较多，是逆时针；负值较多则为顺时针。

2、还有一种说明是取多边形的极点值，多边形的方向和这个顶点与其相邻两边构成的方向相同。

需要注意的是在屏幕坐标中，Y是向下的，所以在屏幕坐标系中看到的顺时针既是在Y轴向上的直角坐标系中看到的逆时针方向。
1.凸包的时候，只要判断前三个点即可，计算叉积，判断方向

2.凹包情况就复杂了，可以从三个方面考虑

首先，可以去凸包上的特殊点，x最大最小的点，y最大最小的点，这些极值点肯定是在凸包上的，可以计算这些的叉积，其次，直接统计叉积正负的数量，正多负少，是逆时针，反之，顺时针。

一个简单的做法是，计算面积，用面积的正负判断方向。


建立多个视图，透视，俯视图，左视图
建立过个场景
再物体本身有旋转的情况下，世界坐标和Local坐标怎么平移



夹角公式：
A1X+B1Y+C1=0........(1)
A2X+B2Y+C2=0........(2)
则(1)的方向向量为u=(-B1,A1)，(2)的方向向量为v=(-B2,A2)
由向量数量积可知，cosφ=u·v/|u||v|，即
两直线夹角公式：cosφ=A1A2+B1B2/[√(A1^2+B1^2)√(A2^2+B2^2)] [3] 
注：k1,k2分别L1,L2的斜率,即tan(α-β)=（tanα-tanβ）/（1+tanαtanβ）

var sin = Math.sin;
var cos = Math.cos;
var pow = Math.pow;
var sqrt = Math.sqrt;
var cosh = Math.cosh;
var sinh = Math.sinh;
var exp = Math.exp;
var PI = Math.PI;
var square = function (x) {
    return x*x;
}
var mod2 = function (a, b) {
    var c = a % b;
    return c > 0 ? c : (c + b);
}

var theta1 = -(20/9) * PI;
var theta2 = 15 * PI;
function getParametricEquation(dx, dy) {
    return {
        u: {
            min: 0,
            max: 1,
            step: 1 / 24
        },
        v: {
            min: theta1,
            max: theta2,
            step: (theta2 - theta1) / 575
        },
        x: function (x1, theta) {
            var phi = (PI/2)*exp(-theta/(8*PI));
            //弧长=(n*π*r)/180。面积=(n*π*r^2)/360=l*r/2。
            var y1 = 1.9565284531299512*square(x1)*square(1.2768869870150188*x1-1)*sin(phi);
            var X = 1-square(1.25*square(1-mod2((3.6*theta),(2*PI))/PI)-0.25)/2;
            var r = X*(x1*sin(phi)+y1*cos(phi));
            return r * sin(theta) + dx;
        },
        y: function (x1, theta) {
            var phi = (PI/2)*exp(-theta/(8*PI));
            var y1 = 1.9565284531299512*square(x1)*square(1.2768869870150188*x1-1)*sin(phi);
            var X = 1-square(1.25*square(1-mod2((3.6*theta),(2*PI))/PI)-0.25)/2;
            var r = X*(x1*sin(phi)+y1*cos(phi));
            return r * cos(theta) + dy;
        },
        z: function (x1, theta) {
            var phi = (PI/2)*exp(-theta/(8*PI));
            var y1 = 1.9565284531299512*square(x1)*square(1.2768869870150188*x1-1)*sin(phi);
            var X = 1-square(1.25*square(1-mod2((3.6*theta),(2*PI))/PI)-0.25)/2;
            var r = X*(x1*sin(phi)+y1*cos(phi));
            return X*(x1*cos(phi)-y1*sin(phi));
        }
    };
}

function createSeries(dx, dy, color) {
    return {
        type: 'surface',
        parametric: true,
        shading: 'realistic',
        silent: true,
        wireframe: {
            show: false
        },
        realisticMaterial: {
            roughness: 0.7,
            metalness: 0,
            textureTiling: [200, 20]
        },
        parametricEquation: getParametricEquation(dx, dy)
    };
}

option = {
    toolbox: {
        feature: {
            saveAsImage: {
                backgroundColor: '#111'
            }
        },
        iconStyle: {
            normal: {
                borderColor: '#fff'
            }
        },
        left: 0
    },
    xAxis3D: {
        type: 'value'
    },
    yAxis3D: {
        type: 'value'
    },
    zAxis3D: {
        type: 'value'
    },
    grid3D: {

        show: false,
        boxWidth: 200,
        boxDepth: 200,

        axisPointer: {
            show: false
        },
        axisLine: {
            lineStyle: {
                color: '#fff'
            }
        },
        postEffect: {
            enable: true,
            SSAO: {
                enable: true,
                radius: 10,
                intensity: 1
            }
        },
        temporalSuperSampling: {
            enable: true
        },
        light: {
            main: {
                intensity: 1,
                shadow: true,
            },
            ambient: {
                intensity: 0
            },
            ambientCubemap: {
                texture: ROOT_PATH + '/data-gl/asset/pisa.hdr',
                exposure: 1,
                diffuseIntensity: 1,
                specularIntensity: 1
            }
        },
        viewControl: {
            // projection: 'orthographic'
        }
    },
    series: [
        createSeries(1.5, 1.5),
        createSeries(-1.5, -1.5),
        createSeries(-1.5, 1.5),
        createSeries(1.5, -1.5),
        createSeries(0, 0),
    ]
};

